
基础路径设置: 
//basePath = D:\project\GitHub\myPython
basePath = Save:node\Pythons\

/***********************************************************************/

//Pythons 练习
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.01\] Hello, World
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.02\] time-------------当前时间戳
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.03\] if .. else ..
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.04\] while, for
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.05\] cmath------------数学
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.06\] list, dict
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.07\] lambda-----------匿名函数
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.08\] match, re--------通配符
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.09\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.10\] np
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.11\] tensor, array
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.12\] 加法乘法
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.13\] * ** 乘方
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.14\] randint
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.15\] import list
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.16\] import
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.17\] global globals()
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.18\] __dict__
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.19\] graph
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.20\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.21\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.22\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.23\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[1.24\] 
// 2. fun
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.1\] str, bytes, bytearray
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.2\] list--------------列表
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.3\] tuple-------------元组
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.4\] dict--------------字典
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.5\] seq---------------序列
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.6\] enumerate---------遍历
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.7\] re
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.8\] class
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.9\] map---------------映射
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.10\] set--------------集合
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.11\] [i for i in x]---列表(/字典/集合)推导式
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.12\] sorted
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.13\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.14\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[2.15\] 
// 3. file
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.1\] pd.read_csv
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.2\] df.sample 随机选取
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.3\] mkdir
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.4\] file
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.5\] pd.concat--------行列连接
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.6\] pd.get_dummies---独热编码
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.7\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.8\] file_read_write
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.9\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[3.10\] 
// 4. lib
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.1\] math
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.2\] copy
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.3\] json
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.4\] six
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.5\] Sklearn
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.6\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.7\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.8\] Keras, TFLearn, Sonnet
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.9\] hook函数
Save:node\Pythons\study\Macro_Pythons_tf1.h \[4.10\] 
// 5. tf
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.1\] tf.Variable()
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.2\] tf.train.Saver.save()
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.3\] tf.add()
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.4\] tf.group(mul, add)
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.5\] tf.gradients-------梯度
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.6\] tf.data.Dataset
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.7\] tf.layers
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.8\] tf.nn.softmax
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.9\] tf.one_hot
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.10\] tf.logging
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.11\] tf.Estimator------评估器
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.12\] tf.Experiment-----实验类
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.13\] tf.Dataset--------数据集
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.14\] layer_norm
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.15\] accuracy----------准确度
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.16\] tf.reshape
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.17\] tf.gather---------索引提取
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.18\] Hook
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.19\] tf_test
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.20\] tf.summary
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.21\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.22\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.23\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.24\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.25\] 
Save:node\Pythons\study\Macro_Pythons_tf1.h \[5.26\] 
// 6. Jieba 练习
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.1\] Jieba--pseg.cut
Save:node\Pythons\study\Macro_Pythons_tf1.h \[6.2\] Jieba--pseg.cut--file
// 其他标号
Save:node\Test\Macro_Tmp_Node_Num.h \[1.1\] 




/***********************************************************************/


[1.01] Hello, World
//	Hello, World:
py_test\test_Hello_World.py
python py_test\test_Hello_World.py



[1.02] time当前时间戳
//time
py_test\test_time.py
python py_test\test_time.py



[1.03] if .. else ..
//if else
py_test\test_if.py
python py_test\test_if.py

//if else
next_sentence_label = 1 if instance.is_random_next else 0



[1.04] while, for
//while
py_test\test_while.py
python py_test\test_while.py



[1.05] 数学 cmath
// cmath
py_test\test_cmath.py
python py_test\test_cmath.py



[1.06] list, dict
//list
py_test\test_list.py
python_w py_test\test_list.py

//dict
py_test\test_dict.py
python_w py_test\test_dict.py

// 遍历元组
py_test\test_tuple.py
python_w py_test\test_tuple.py
	

// 相互转换的方法
py_test\test_list_trans.py
python_w py_test\test_list_trans.py



[1.07] lambda-----------匿名函数
//lambda
py_test\test_lambda.py
python py_test\test_lambda.py




[1.08] match, re--------通配符
//re
py_test\test_re.py
python py_test\test_re.py


//match
py_test\test_re_match.py
python py_test\test_re_match.py



[1.09] 




[1.10] np
//	ERR：
py_test\test_np.py
python py_test\test_np.py




[1.11] tensor, array
//	tensor转array:
py_test\test_shape.py
python_w py_test\test_shape.py




[1.12] 加法乘法
//one_hot
py_test\test_op.py
python_w py_test\test_op.py

//+
py_test\test_op1.py
python_w py_test\test_op1.py

//*
py_test\test_op2.py
python_w py_test\test_op2.py

//tf.concat
py_test\test_op3.py
python_w py_test\test_op3.py

//tf.concat
py_test\test_op4.py
python_w py_test\test_op4.py




[1.13] * ** 乘方
//*  代表乘法
//*  表示倍数 ‘aaa’*3
//参数:
def demo(*p):  是用来接受任意多个参数并将其放在一个元组中
def d(a,b,c):  d(*[1,2,3]), 自动进行解包然后传递给多个单变量参数（参数个数要对应相等）

//** 代表乘方
//参数:
def demo(**p):	**parameter用于接收类似于关键参数一样赋值的形式的多个实参放入字典中（即把该函数的参数转换为字典）。


[1.14] randint
//rand
py_test\test_rand.py
python_w py_test\test_rand.py



[1.15] import list

import os
import modeling
import optimization
import tensorflow as tf
import logging  
import logging.handlers
import sys
import time



[1.16] import
//import 语句:
import module1[, module2[,... moduleN]]
import random
//
random.randint(1, 10)
//导入多个模块：
import math, sys, random, os

//from import 语句:
//导入random模块下的所有函数：
from moduleName import name1[, name2[, ... nameN]]|*

from random import *
//不需要前缀
//	randint(1, 10)

//导入多个模块：
from random import randint, random


//从datetime包中只导入datetime这个类
from datetime import datetime




[1.17] global globals()
若想在函数内部对函数外的变量进行操作，就需要在函数内部声明其为global。


globals()
globals() 函数会以字典类型返回当前位置的全部全局变量。




[1.18] __dict__
//	class A(object):
//	obj = A()
//
//	print (A.__dict__)
//		{'a': 0, '__module__': '__main__', 'b': 1, , '__dict__':<> , '__init__':<> , 'test':<> , '__weakref__': <>, '__doc__': '', 'static_test': <>}
//	print (obj.__dict__)
//		{'a': 2, 'b': 3}




[1.19] graph
//tf.graph
py_test\tf_graph.py
python_w py_test\tf_graph.py



[1.20] 




[1.21] 




[1.22] 




[1.23] 




[1.24] 




[1.25] 




[1.26] 






[2.1] str, bytes, bytearray
//strip
str.strip()  移除字符串头尾指定的字符

str.join()  连接字符串数组。将字符串、元组、列表中的元素以指定的字符(分隔符)连接生成一个新的字符串
//	a=['1','2','3','4','5']
//	print('  '.join(a))
//	1 2 3 4 5

str.split()
str.split(str="", num=string.count(str)).
//str -- 分隔符，默认为所有的空字符，包括空格、换行(\n)、制表符(\t)等。
//num -- 分割次数。默认为 -1, 即分隔所有。

ord(char) chr(48) unichr(48)  ASCII/Unicode码

//str --> bytes (encode) -------------------------- encode()
//	str="aabbcc"
//	bytes=str.encode('utf-8')

//bytes --> str (decode) -------------------------- decode()
//	bytes=b"aabbcc"
//	str=bytes.decode('utf-8')

//str,bytes --> bytearray ------------------------- bytearray()
//	bytes=b"aabbcc"
//	byarray=bytearray(bytes)
//	str="aabbcc"
//	byarray=bytearray(str)

//hex_str --> bytearray --------------------------- bytearray.fromhex()
//	hexstr="098811"
//	byarray=bytearray.fromhex(hexstr)
//	print(byarray)
//	bytearray(b'\t\x88\x11')

//bytearray --> str,bytes -------------------------- decode(), bytes()
//	byarray=bytearray("aabbcc",encoding='utf-8')
//	str=byarray.decode('utf-8')
//	bytes=bytes(byarray)



[2.2] list---列表
range() 函数可创建一个整数列表

//	s1=set([])　＃列表
//	s2=set(())　＃元组
//	s3=set({})　＃字典


[2.3] tuple--元组
zip()  接受任意多个（包括0个和1个）序列作为参数，返回一个tuple列表
//xyz = zip(x, y, z)
//      zip([1, 4, 7], [2, 5, 8], [3, 6, 9])
//      [(1, 4, 7), (2, 5, 8), (3, 6, 9)]
//u   = zip(*xyz)
//      [(1, 2, 3), (4, 5, 6), (7, 8, 9)]
//r   = zip(* [x] * 3)
//      [(1, 1, 1), (2, 2, 2), (3, 3, 3)]

//	tuple([1,2,3,4])
//		(1, 2, 3, 4)
//	tuple({1:2,3:4})    #针对字典 会返回字典的key组成的tuple
//		(1, 3)
//	tuple((1,2,3,4))    #元组会返回元组自身
//		(1, 2, 3, 4)
	

[2.4] dict---字典
dict()  使用zip创建字典
//dict(zip(key, value))
//      {‘a‘: 1, ‘b‘: 2, ‘c‘: 3}
//dict(dict1, **dict2) 连接两个字典

fromkeys()  创建一个新字典，以序列seq中元素做字典的键，value为字典所有键对应的初始值。
//d=dict.fromkeys(seq,100)

//tn = dict.get(tensor_name, 0)


[2.5] seq----序列
//	seq={‘name‘,‘age‘,‘score‘}

//	seq = ['one', 'two', 'three']
//	for i, element in enumerate(seq):
//		print i, element
//		0 one
//		1 two
//		2 three


[2.6] enumerate----遍历
enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。

//	rdm = np.random.mtrand.RandomState(SEED)
//	X = rdm.rand(32, 2)
//	Y_ = [[int(x0 + x1 < 1)] for (x0, x1) in X]


//遍历字典dict
//	for i in dict: 
//	    print "dict[%s]=" % i,dict[i] 

//	for (k,v) in  dict.items(): 
//	     print "dict[%s]=" % k,v 

//	for k,v in dict.iteritems(): 
//	     print "dict[%s]=" % k,v 

//	for k,v in zip(dict.iterkeys(),dict.itervalues()): 
//	     print "dict[%s]=" % k,v 




[2.7] re
compile()  返回的是一个匹配对象，它单独使用就没有任何意义，需要和findall(), search(), match()搭配使用。 
//	regex = re.compile('\w*o\w*')
//		x = regex.findall(content)


escape()  可以对字符串中所有可能被解释为正则运算符的字符进行转义的应用函数
//  re.escape('www.python.org')
'www\\.python\\.org'
//  re.findall(re.escape('w.py'),"jw.pyji w.py.f")
['w.py', 'w.py']


sub()  是substitude的缩写，表示替换
//  re.sub(r'\w+','10',"xy 15 rt 3e,gep",2,flags=re.I )
'10 10 rt 3e,gep'，

//	string = 'apple pear banana meat'
//	re.sub(r'(apple|banana)\s(\w+)\s?', lambda x: func(ret, x.group(1), x.group(2)), string)
{'apple': 'pear', 'banana': 'meat'}


[2.8] class


[2.9] map 映射
map()  	会根据提供的函数对指定序列做映射。
第一个参数 function 以参数序列中的每一个元素调用 function 函数，返回包含每次 function 函数返回值的新列表。
//  def square(x) : ...		   # 计算平方数
//  map(square, [1,2,3,4,5])   # 计算列表各个元素的平方
[1, 4, 9, 16, 25]
//  map(lambda x: x ** 2, [1, 2, 3, 4, 5])	# 使用 lambda 匿名函数
[1, 4, 9, 16, 25]
//  提供了两个列表，对相同位置的列表数据进行相加
//  map(lambda x, y: x + y, [1, 3, 5, 7, 9], [2, 4, 6, 8, 10])
[3, 7, 11, 15, 19]


[2.10] set----集合
集合是一个无序不重复元素的集

//	s1=set([])　＃列表
//	s2=set(())　＃元组
//	s3=set({})　＃字典

//	s1=set([1,2,3,4])
//	{1, 2, 3, 4}
//	　　
//	s3=set({'a':2,'b':3,'c':4})
//	{'c', 'a', 'b'}

set1.add('vivi')
set1.update('abc')
set1.pop()
set1.remove('haha')
set1.clear()
del set1


[2.11] [i for i in x]---列表(/字典/集合)推导式
//列表推导式
//	[i for i in range(30) if i % 3 is 0]
//	  [0, 3, 6, 9, 12, 15, 18, 21, 24, 27]

//generator
//	list = [x for x in range(10)]
//	for x in enumerate(list):
//	    print(x,end=' ')
//	# (0, 0) (1, 1) (2, 2) (3, 3) (4, 4) (5, 5) (6, 6) (7, 7) (8, 8) (9, 9)
//	print()
//	generator = (x for x in range(10))
//	for x in generator:
//	    print(x,end=" ")
//	# 0 1 2 3 4 5 6 7 8 9

//字典推导式
//	mcase = {'a': 10, 'b': 34}
//	mcase_frequency = {v: k for k, v in mcase.items()}
//	{10: 'a', 34: 'b'}

//集合推导式
//	{x**2 for x in [1, 1, 2]}
//	set([1, 4])


[2.12] 
sorted(dict.items(),key=lambda item:item[0])

//	列表排序反向顺序?
newsort = sorted(sort,key=operator.itemgetter(1), reverse = True)


[2.13] 


[2.14] 


[2.15] 




[3.1] pd.read_csv
//	read_csv
q_table6 = pd.read_csv('dl_data.csv',encoding = "utf-8",header = 0,names = range(0,50))
q_table6 = pandas.read_csv(filepath_or_buffer, sep=', ', delimiter=None, header='infer', names=None, 
			index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, 
			engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, 
			skiprows=None, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, 
			skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, 
			dayfirst=False, iterator=False, chunksize=None, compression='infer', thousands=None, decimal=b'.', 
			lineterminator=None, quotechar='"', quoting=0, escapechar=None, comment=None, encoding=None, 
			dialect=None, tupleize_cols=None, error_bad_lines=True, warn_bad_lines=True, skipfooter=0, 
			doublequote=True, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None）

//	不想添加新的行索引
//		index_col=0表示以原有数据的第一列(索引为0)当作行索引。
q_table6 = pd.read_csv('dl_data.csv',encoding = "utf-8",index_col=0)

//	sep=','   # 以，为数据分隔符
//	shkiprows= 10   # 跳过前十行
//	nrows = 10   # 只去前10行
//	parse_dates = ['col_name']   # 指定某行读取为日期格式
//	index_col = ['col_1','col_2']   # 读取指定的几列
//	error_bad_lines = False   # 当某行数据有问题时，不报错，直接跳过，处理脏数据时使用
//	na_values = 'NULL'   # 将NULL识别为空值


[3.2] df.sample 随机选取
df = df.sample(frac=1, random_state = 94).reset_index(drop=True)
DataFrame.sample(n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)[source]

//抽取行的比例 frac=0.8
//random_state=None,取得数据不重复


//reset_index
//数据清洗时，会将带空值的行删除，此时DataFrame或Series类型的数据不再是连续的索引，可以使用reset_index()重置索引。
//print(df.reset_index())
//	   index   0   1   2   3
//	0      1   0   1   2   3
//	1      3   4   5   6   7
//	2      4   8   9  10  11
//	3      6  12  13  14  15
//	4      8  16  17  18  19
//
//不想保留原来的index，使用参数 drop=True，默认 False。
df.reset_index(drop=True)
//
result = pd.concat(frames) 
//这句话改成 
result = pd.concat(frames,ignore_index=True)


[3.3] mkdir
	
if not os.path.exists(self.data_dir):
	os.mkdir(self.data_dir)



[3.4] pd.concat
//将数据根据不同的轴作简单的融合 
//	frames = [df1, df2, df3]
//	result = pd.concat(frames)

//要在相接的时候在加上一个层次的key来识别数据源自于哪张表，可以增加key参数
//	result = pd.concat(frames, keys=['x', 'y', 'z'])

//横向表拼接
//	result = pd.concat([df1, df4], axis=1)

//加上join参数的属性，如果为’inner’得到的是两表的交集，如果是outer，得到的是两表的并集。
//	result = pd.concat([df1, df4], axis=1, join='inner')


[3.5] 



[3.6] pd.get_dummies---独热编码
//独热编码
//pd.get_dummies

//sklearn
//	enc = preprocessing.OneHotEncoder()
//	enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])	 # fit来学习编码
//	enc.transform([[0, 1, 3]]).toarray()	# 进行编码
//
//输出：	
//      array([[ 1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.]])

//tf.one_hot()
//	abels = tf.constant([0,1,2]) # 输入的元素值最小为0，最大为2
//	output = tf.one_hot(labels,classes)
//输出：	
//      array([[ 1.,  0.,  0.],
//             [ 0.,  1.,  0.],
//             [ 0.,  0.,  1.]], dtype=float32))


[3.7] 



[3.8] file_read_write
py_test\file_read_c.txt

//write
py_test\file_write.py
python_w py_test\file_write.py


//write try
py_test\file_write1.py
python_w py_test\file_write1.py


//write with 
py_test\file_write2.py
python_w py_test\file_write2.py


//read
//py_test\file_read1.py
//python_w py_test\file_read1.py


//read jieba
//py_test\file_read.py
//python_w py_test\file_read.py



[3.9] 


[3.10] 




[4.1] math
Softmax 归一化指数函数




[4.2] copy
//复制
list1 = copy.copy(list)
//深复制
list2 = copy.deepcopy(list)




[4.3] json




[4.4] six
six.iteritems(json_object)




[4.5] Sklearn
Sklearn 包含了很多种机器学习的方式:
Classification 分类
Regression 回归
Clustering 非监督分类
Dimensionality reduction 数据降维
Model Selection 模型选择
Preprocessing 数据预处理


[4.6] 



[4.7] 




[4.8] 




[4.9] 




[4.10] 






[5.1] tf.Variable()
v1=tf.Variable(tf.random_normal(shape=[4,3],mean=0,stddev=1),name='v1')
//	[[-1.2115501? ?1.0484737? ?0.55210656]
//	?[-1.5301195? ?0.9060654? -2.6766613 ]
//	?[ 0.27101386 -0.32336152? 0.44544214]
//	?[-0.0120788? -0.3409422? -0.48505628]]
v2=tf.Variable(tf.constant(2),name='v2')
//	2
v3=tf.Variable(tf.ones([4,3]),name='v3')
//	[[1. 1. 1.]
//	?[1. 1. 1.]
//	?[1. 1. 1.]
//	?[1. 1. 1.]]

//生成tensor
tf.zeros(shape, dtype=tf.float32, name=None)
tf.zeros_like(tensor, dtype=None, name=None)
tf.constant(value, dtype=None, shape=None, name='Const')
tf.fill(dims, value, name=None)
tf.ones_like(tensor, dtype=None, name=None)
tf.ones(shape, dtype=tf.float32, name=None)

//生成序列
tf.range(start, limit, delta=1, name='range')
tf.linspace(start, stop, num, name=None)

//生成随机数
tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)
tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)
tf.random_uniform(shape, minval=0.0, maxval=1.0, dtype=tf.float32, seed=None, name=None)
tf.random_shuffle(value, seed=None, name=None)


[5.2] tf.train.Saver.save()
//保存图的变量
save_path = saver.save(sess, "/tmp/model.ckpt")
//加载图的变量
saver.restore(sess, "/tmp/model.ckpt")




[5.3] tf.add()
tf.add()
tf.assign_add(x, 1)
tf.multiply(w, 2)


//	with tf.control_dependencies([x_plus_1]):
//	y = tf.identity(x)
//	y.eval()

py_test\op_identity.py
python_w py_test\op_identity.py



[5.4] tf.group(mul, add)
tf.group(mul, add)
tf.tuple([mul, add])


py_test\op_group.py
python_w py_test\op_group.py



[5.5] tf.gradients 梯度
//
py_test\gradients1.py
python_w py_test\gradients1.py
//	[array([1., 1., 1.], dtype=float32), 
//	array([1., 1., 1.], dtype=float32), 
//	array([2., 2., 2.], dtype=float32), 
//	array([1., 1., 1.], dtype=float32)]


py_test\gradients2.py
python_w py_test\gradients2.py
//	[array([2., 2., 3.], dtype=float32), 
//	array([2., 2., 3.], dtype=float32), 
//	array([5., 4., 7.], dtype=float32), 
//	array([3., 2., 4.], dtype=float32)]


py_test\gradients3.py
python_w py_test\gradients3.py
//	the gradient of y=x[0, 0]+2*x[0, 1]for x is: [array([[1., 2.]], dtype=float32)]


py_test\gradients4.py
python_w py_test\gradients4.py
//	[(3.0, 4.0)]
//	[3.0, 4.0, 12.0]


//----手动验证
py_test\gradients5.py
python_w py_test\gradients5.py
//	[(3.0, 5.0)]
//	[3.0, 5.0, 14.0]



[5.6] tf.data.Dataset
py_test\data_Dataset1.py
python_w py_test\data_Dataset1.py
//	1.0
//	2.0
//	3.0
//	4.0
//	5.0

//----list
py_test\data_Dataset2.py
python_w py_test\data_Dataset2.py
//	[0.50283511 0.3921546 ]
//	[0.53019523 0.78479929]
//	[0.2543726	0.62849479]
//	[0.22100771 0.48973158]
//	[0.71914178 0.67568286]
//	end!

//----disk
py_test\data_Dataset3.py
python_w py_test\data_Dataset3.py
//	{'a': 1.0, 'b': array([0.79249911, 0.15798004])}
//	{'a': 2.0, 'b': array([0.34127329, 0.56827207])}
//	{'a': 3.0, 'b': array([0.8322679 , 0.61611865])}
//	{'a': 4.0, 'b': array([0.65949827, 0.6437763 ])}
//	{'a': 5.0, 'b': array([0.50562221, 0.37971811])}
//	end!

//----tuple
py_test\data_Dataset4.py
python_w py_test\data_Dataset4.py
//	(1.0, array([0.25269596, 0.98681773]))
//	(2.0, array([0.72293645, 0.08887966]))
//	(3.0, array([0.09073945, 0.42811984]))
//	(4.0, array([0.59848085, 0.00249306]))
//	(5.0, array([0.66916095, 0.45611585]))
//	end!

//----map
py_test\data_Dataset5.py
python_w py_test\data_Dataset5.py
//	2.0
//	3.0
//	4.0
//	5.0
//	6.0
//	end!

//----batch--将多个元素组合成batch
py_test\data_Dataset6.py
python_w py_test\data_Dataset6.py
//	{'a': array([1., 2.]), 'b': array([[0.28226126, 0.32874466],
//		   [0.1308661 , 0.07176781]])}
//	{'a': array([3., 4.]), 'b': array([[0.823813  , 0.20713728],
//		   [0.75160344, 0.94561941]])}
//	{'a': array([5.]), 'b': array([[0.21681289, 0.56474561]])}
//	end!

//----shuffle--打乱
py_test\data_Dataset7.py
python_w py_test\data_Dataset7.py
//	{'a': 2.0, 'b': array([0.61422834, 0.68408869])}
//	{'a': 1.0, 'b': array([0.057589  , 0.05745147])}
//	{'a': 3.0, 'b': array([0.59370247, 0.20736014])}
//	{'a': 4.0, 'b': array([0.05181975, 0.67037327])}
//	{'a': 5.0, 'b': array([0.10704603, 0.72817143])}
//	end!


//----repeat--将整个序列重复多次
py_test\data_Dataset8.py
python_w py_test\data_Dataset8.py
//	{'a': 1.0, 'b': array([0.51900078, 0.10005534])}
//	{'a': 2.0, 'b': array([0.8865739 , 0.38145213])}
//	{'a': 3.0, 'b': array([0.68661129, 0.53582187])}
//	{'a': 4.0, 'b': array([0.61606895, 0.04549935])}
//	{'a': 5.0, 'b': array([0.96872654, 0.04734563])}
//	{'a': 1.0, 'b': array([0.51900078, 0.10005534])}
//	{'a': 2.0, 'b': array([0.8865739 , 0.38145213])}
//	{'a': 3.0, 'b': array([0.68661129, 0.53582187])}
//	{'a': 4.0, 'b': array([0.61606895, 0.04549935])}
//	{'a': 5.0, 'b': array([0.96872654, 0.04734563])}
//	end!




[5.7] tf.layers

py_test\layers_dense.py
python_w py_test\layers_dense.py




[5.8] tf.nn.softmax
//tf.nn.log_softmax

py_test\log_softmax.py
python_w py_test\log_softmax.py


//信息熵(真实*真实)
//	代表的是随机变量或整个系统的不确定性，熵越大，随机变量或系统的不确定性就越大
//	sum(p*log2(1/p)) = 1/2*log2(2)+...= 1/2 * 1 + 1/4 * 2 + 1/8 * 3 + 1/8 * 3 = 1.75
//
//	sum(10个,不平均) = 0.9 * 0.152 + 0.0111 * 6.49 * 9 = 0.785
//	sum(10个,平均)	   = 0.1 * 3.32 * 10				 = 3.32


//交叉熵(真实*非真实)
//	真实分布为基础，非真实分布策略树求和;
//	sum(p*log2(1/q)) = 1/2*log2(4)+... = 2
//
//	sum(10个,不平均) = 0.9 * 3.32 + 0.0111 * 3.32 * 9 = 3.32
//	sum(10个,平均)	   = 0.1 * 3.32 * 10				= 3.32

//相对熵(交叉熵 - 信息熵)
//	KL(p || q) = H(p，q) - H(p) = 2 - 1.75 = 0.25
//	KL(10个,不平均) = 3.32 - 0.785			   = 2.53



[5.9] tf.one_hot

py_test\tf_one_hot.py
python_w py_test\tf_one_hot.py




[5.10] tf.logging

tf.logging.info(">>>instance--%s : %s" %( str(inst_index), str(instance)))

print(one_hot_1.eval(session=sess))

sess.run(tf.Print(train_logits,[train_logits],summarize=134))





[5.11] Estimator------评估器

//Estimator
py_test\tf_Estimator.py
//python_w py_test\tf_Estimator.py


[5.12] tf.Experiment-----实验类
//Experiment（实验）类是定义如何训练模型，并将其与 Estimator 进行集成的方式。




[5.13] tf.Dataset--------数据集

py_test\tf_Dataset.py
//python_w py_test\tf_Dataset.py



[5.14] layer_norm

layer_norm		   
在张量的最后一个维度上运行图层规范化




[5.15] tf.metrics.accuracy 准确度
//accuracy
py_test\tf_accuracy.py
python_w py_test\tf_accuracy.py

//f1score
py_test\tf_metrics_f1score.py
python_w py_test\tf_metrics_f1score.py


//sklearn
py_test\sklearn_metrics1.py
python_w py_test\sklearn_metrics1.py



[5.16] tf.reshape
py_test\test_reshape.py
python_w py_test\test_reshape.py



[5.17] tf.gather---------索引提取
//tf.gather：用一个一维的索引数组，将张量中对应索引的向量提取出来
py_test\test_gather.py
python_w py_test\test_gather.py



[5.18] Hook



[5.19] tf_test
run_tf_test.py



[5.20] tf.summary

//tf.summary
py_test\tf_summary.py
python_w py_test\tf_summary.py
//	AttributeError: module 'tensorflow' has no attribute 'assign_add'







[5.21] 



[5.22] 



[5.23] 



[5.24] 



[5.25] 



[5.26] 






//Jieba 练习
[6.1] Jieba--pseg.cut
//	我, r
//	爱, v
//	北京, ns
//	天安门, ns

py_test\jieba_cut.py
python py_test\jieba_cut.py


[6.2] Jieba--pseg.cut--file
py_test\jieba_cut_a.txt
//我爱北京天安门 
py_test\jieba_cut_b.txt
//我r	爱v  北京ns	天安门ns   x 

py_test\file_read.py
python_w py_test\file_read.py

















